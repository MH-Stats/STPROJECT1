[
  {
    "objectID": "ST558_Project_1.html",
    "href": "ST558_Project_1.html",
    "title": "ST558",
    "section": "",
    "text": "The Public Use Microdata Sample (PUMS) Census API is a freely available resource that anyone can access to acquire pseudo person-level data collected for the U.S census. In order to access this immense data set we will have to interact with the application program interface (API), which is a set of protocols and rules that allows applications to communicate with a database. In this case we are going to be using R in order to access the API, and to start we are going to need to load in some very useful packages.\nPlease read the notes in the code chunk below to better understand why we are loading in these packages:\n\nlibrary(tidycensus) #Package built to allow users to return Census Bureau API data as tibbles\nlibrary(httr) #Provides a list of easy to use statements like get() for APIs\nlibrary(jsonlite) #Package that provides a JSON parser and generator\nlibrary(dplyr) \n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tibble) #Used to create tibbles and is a part of tidyverse\nlibrary(ggplot2) #Used for plotting\nlibrary(tidyr) #Used to make data \"wide\"\nlibrary(hms) #Converts 00:00 or 00:00:00 to a time variable\nlibrary(lubridate) \n\n\nAttaching package: 'lubridate'\n\n\nThe following object is masked from 'package:hms':\n\n    hms\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\n\n\n\nThe next step we need to take is to create a helper function to assist with the query process for APIs. This function will convert the raw content to character strings, parse the JSON data, and then convert the data into a tibble. If you read through you will see that additional code has been added on that will further assist with the processing of the data we will receive from the query process. The added on functions will be explained in details later on in this document.\n\n# Helper function to process API response\nprocess_api_response &lt;- function(api_response) {\n  # Check if the response was successful\n  if (api_response$status_code != 200) {\n    stop(\"Error: API request failed with status code \", api_response$status_code)\n  }\n  \n  # Convert raw content to character string\n  content_string &lt;- rawToChar(api_response$content)\n  \n  # Parse JSON data\n  parsed_data &lt;- fromJSON(content_string)\n  \n  # First row contains column names, the rest is the data\n  column_names &lt;- parsed_data[1, ]\n  data_rows &lt;- parsed_data[-1, ]\n  \n  # Convert to tibble and set column names\n  tibble_data &lt;- as_tibble(data_rows)\n  colnames(tibble_data) &lt;- column_names\n  \n  #creating new variable in order to check if variables are numeric\n  valid_numeric_vars &lt;- c(\"AGEP\", \"GASP\", \"GRPIP\", \"JWAP\", \"JWDP\", \"JWMNP\", \"PWGTP\")\n   \n  #Created loop to convert proper numeric variables to numeric\n  for(var in colnames(tibble_data)){\n    if(var %in% valid_numeric_vars){\n      tibble_data[[var]] &lt;- as.numeric(tibble_data[[var]])\n    }\n  }\n  #New variable to check for categorical variables\n  valid_categorical_vars &lt;- c(\"FER\", \"HHL\", \"HISPEED\", \"JWTRNS\", \"SCH\", \"SCHL\", \"SEX\")\n  \n  #Created loop to convert proper categorical variables to factor\n  for(var in colnames(tibble_data)){\n    if(var %in% valid_categorical_vars){\n      tibble_data[[var]] &lt;- as.factor(tibble_data[[var]])\n    }\n  }\n  #Creating levels for each categorical variable\n  if (\"SEX\" %in% colnames(tibble_data)) {\n    tibble_data &lt;- tibble_data |&gt;\n      mutate(\n        SEX = factor(SEX, labels = SEX_levels))\n  }\n    if (\"SCHL\" %in% colnames(tibble_data)) {\n    tibble_data &lt;- tibble_data |&gt;\n      mutate(\n        SCHL = factor(SCHL, labels = SCHL_levels))\n  }\n  if (\"SCH\" %in% colnames(tibble_data)) {\n    tibble_data &lt;- tibble_data |&gt;\n      mutate(\n        SCH = factor(SCH, labels = SCH_levels))\n  }\n    if (\"JWTRNS\" %in% colnames(tibble_data)) {\n    tibble_data &lt;- tibble_data |&gt;\n      mutate(\n        JWTRNS = factor(JWTRNS, labels = JWTRNS_levels))\n    }\n    if (\"HISPEED\" %in% colnames(tibble_data)) {\n    tibble_data &lt;- tibble_data |&gt;\n      mutate(\n        HISPEED = factor(HISPEED, labels = HISPEED_levels))\n    }\n    if (\"HHL\" %in% colnames(tibble_data)) {\n    tibble_data &lt;- tibble_data |&gt;\n      mutate(\n         HHL = factor(HHL, labels =  HHL_levels))\n    }\n    if (\"FER\" %in% colnames(tibble_data)) {\n    tibble_data &lt;- tibble_data |&gt;\n      mutate(\n         FER = factor(FER, labels = FER_levels))\n  }\n  #Pasting correct time values in for JWAP\n  if(\"JWAP\" %in% colnames(tibble_data)) {\n  tibble_data &lt;- tibble_data |&gt;\n   left_join(JWAP_intervals, join_by(JWAP)) |&gt;\n    rename(work_arrival_time = middle_time,\n           arrival_meridiem = meridiem) |&gt;\n    select(-JWAP)\n  } \n  \n  #Pasting correct time values in for JWDP\n   if(\"JWDP\" %in% colnames(tibble_data)) {\n  tibble_data &lt;- tibble_data |&gt;\n   left_join(JWDP_intervals, join_by(JWDP)) |&gt;\n    rename(work_departure_time = middle_time2,\n           departure_meridiem = meridiem2) |&gt;\n    select(-JWDP)\n  } \n  \n  return(tibble_data)\n}\n\nThe next step is to create a year validation function in order to confirm only the correct years (2022 to 2010) are queried by the user. This function alongside other subsequent ones will be added to the main API query that we are creating, that way we can insure a user only selects variables that will work with our API query.\n\n# Function to validate the year\nvalidate_year &lt;- function(year) {\n  cat(\"API year is :\", year)\n  if (year &lt; 2010 || year &gt; 2022) {\n    stop(\"Invalid year. Year must be between 2010 and 2022.\")\n  }\n}\n\nAfter we create our year validation function we make another function that insures our user will only select the valid numeric and categorical variables our query will work with, and if the user does not select these variables they will get an error message letting them know what variables they can use instead. Additionally, the function insures that the PWGTP variable is always included with our query, as that variable is a representation of the number of people each row actually represents, specifically it is our weight variable.\n\n# Function to validate numeric variables\nprocess_numeric_vars &lt;- function(numeric_vars = c(\"AGEP\", \"PWGTP\")) {\n  valid_numeric_vars &lt;- c(\"AGEP\", \"GASP\", \"GRPIP\", \"JWAP\", \"JWDP\", \"JWMNP\", \"PWGTP\")\n  \n  # Check PWGTP is always included\n  if (!\"PWGTP\" %in% numeric_vars) {\n    numeric_vars &lt;- c(numeric_vars, \"PWGTP\")\n  }\n  \n  # Validate numeric variables\n  if (!all(numeric_vars %in% valid_numeric_vars)) {\n    stop(\"Invalid numeric variables. Valid options: AGEP, GASP, GRPIP, JWAP, JWDP, JWMNP, PWGTP.\")\n  }\n  \n  # Check at least one numeric variable other than PWGTP\n  if (!any(numeric_vars %in% valid_numeric_vars[valid_numeric_vars != \"PWGTP\"])) {\n    stop(\"At least one numeric variable other than PWGTP must be returned.\")\n  } \n} \n\n# Function to validate categorical variables\nprocess_categorical_vars &lt;- function(categorical_vars = c(\"SEX\")) {\n  valid_categorical_vars &lt;- c(\"FER\", \"HHL\", \"HISPEED\", \"JWTRNS\", \"SCH\", \"SCHL\", \"SEX\")\n  \n  # Validate categorical variables\n  if (!all(categorical_vars %in% valid_categorical_vars)) {\n    stop(\"Invalid categorical variables. Valid options: FER, HHL, HISPEED, JWAP, JWDP, JWTRNS, SCH, SCHL, SEX.\")\n  }\n  return(categorical_vars)\n}\n\nLooking ahead when we pull the time variables JWAP and JWDP out of the API they appear as character strings that represent a time interval for the period in which a person generally begins work, such as 09:00 a.m to 09:04 a.m. This proves to be a problem for us as we we can not present the interval in a neat easily understandable manner for the user, so to make things more consistent and readable we will have the time variables return as the middle time between the interval. To do this is quite a complicated tasks, and will require the usage of the readr which will allow us to separate the character strings into usable columns. Due to the complexity of this we are going to extract the exact data for the whole variable in the API, then use separate_wider_delim to create two columns that represent the start and end of the time variable. Since the time variables are represented in the character strings as “00:00” we can use the parse_hm() function to have the columns for the start and end of the intervals represented in HH:MM:SS format, once they are in that format the start and end columns can be subtracted then divided by two and added to the start to get the middle of the interval for each observation. In order to aid readability the time variables are going to be renamed to work_arrival_time or work_departure_time, in addition the proper am or pm designation columns (meridian) will appear next to the variables. That way the user will still be able to manipulate the variables as a time variable and know if the variable is for the morning or night.\n\n# Function to process time variables\nprocess_time_variable &lt;- function(variable_name) {\n \n   # Grabbing information from API\n  temp &lt;- httr::GET(paste0(\"https://api.census.gov/data/2022/acs/acs1/pums/variables/\", variable_name, \".json\"))\n  temp_list &lt;- temp$content |&gt; rawToChar() |&gt; jsonlite::fromJSON()\n  \n  # Getting just the variable names and their values\n  time_values &lt;- temp_list$values$item\n  time_vals_sorted &lt;- time_values[sort(names(time_values))]\n  \n  # Converting the values into a tibble\n  time_tibble &lt;- tibble(id = seq(0, length(time_vals_sorted) - 1), value = time_vals_sorted)\n  \n  # Converting to wide format\n  time_wide &lt;- separate_wider_delim(time_tibble, \n                                     cols = c(\"value\"), \n                                     delim = \" \", \n                                     names = c(\"start\", \"meridiem\", \"to\", \"end\", \"meridiem_2\"), \n                                     too_few = \"debug\", \n                                     names_repair = \"unique\", \n                                     too_many = \"drop\") \n  \n  # Select the needed rows and convert to usable format\n  time_intervals &lt;- time_wide |&gt;\n    select(id, start, meridiem, end, meridiem_2) |&gt; #meridiem is to track if values were for am or pm\n    mutate(start = parse_hm(start),\n           end = parse_hm(end),\n           variable_name = id)  \n  \n  # Make row 1 display NA across all columns for row 1    \n  time_intervals[1, ] &lt;- NA\n  \n  # Creating middle time value variable\n  time_intervals &lt;- time_intervals |&gt;\n    mutate(interval = (end - start) / 2,\n           interval = as.numeric(interval),\n           interval = as.period(interval))\n\n  # Turning start into a period   \n  time_intervals &lt;- time_intervals |&gt;\n    mutate(start = as.period(start),\n           middle_time = as.duration(start + interval)) |&gt;\n    select(middle_time, variable_name, meridiem) \n  \n  # Turning the first row variable back to 0\n  time_intervals[1, 2] &lt;- 0\n          \n  # Converting back to a time variable        \n  time_intervals &lt;- time_intervals |&gt;\n    mutate(middle_time = hms::hms(seconds = middle_time))\n  \n  return(time_intervals)\n} \n\n#Renaming variables to insure they work in the helper function\nJWAP_intervals &lt;- process_time_variable(\"JWAP\")\n\nWarning: Debug mode activated: adding variables `value_ok`, `value_pieces`, and\n`value_remainder`.\n\nJWAP_intervals &lt;- JWAP_intervals |&gt;\n  rename(JWAP = variable_name)\n         \nJWDP_intervals &lt;- process_time_variable(\"JWDP\")\n\nWarning: Debug mode activated: adding variables `value_ok`, `value_pieces`, and\n`value_remainder`.\n\nJWDP_intervals &lt;- JWDP_intervals |&gt;\n  rename(JWDP = variable_name,\n         middle_time2 = middle_time,\n         meridiem2 = meridiem)\n\nWhen we look at ahead we realize that if we pull in our categorical data we will not necessarily understand it as it is lacking the proper levels for the data contained, necessitating that we create proper level keys for the variables we will be querying. This will follow a similar process to how we got the time variables, but will be much simpler. Once we acquire the necessary levels we will go back in to our helper function to convert the categorical variables to factors and include the proper levels and labels for each one.\n\n# Function to process categorical variables\nprocess_cat_variable &lt;- function(variable_name) {\n \n   # Grabbing information from API\n  temp &lt;- httr::GET(paste0(\"https://api.census.gov/data/2022/acs/acs1/pums/variables/\", variable_name, \".json\"))\n  temp_list &lt;- temp$content |&gt; rawToChar() |&gt; jsonlite::fromJSON()\n  \n  # Getting just the variable names and their values\n  cat_values &lt;- temp_list$values$item\n  cat_vals_sorted &lt;- cat_values[sort(names(cat_values))]\n  \n  # Converting the values into a tibble\n  cat_tibble &lt;- tibble(id = seq(0, length(cat_vals_sorted) - 1), value = cat_vals_sorted)\n  cat_vector &lt;- cat_tibble$value\n  \n  return(cat_vector)\n}\n\n#Running function for categorical variables to store levels\nSCHL_levels &lt;- process_cat_variable(\"SCHL\")\nSEX_levels &lt;- process_cat_variable(\"SEX\")\nSCH_levels &lt;- process_cat_variable(\"SCH\")\nJWTRNS_levels &lt;- process_cat_variable(\"JWTRNS\")\nHISPEED_levels &lt;- process_cat_variable(\"HISPEED\")\nHHL_levels &lt;- process_cat_variable(\"HHL\")\nFER_levels &lt;- process_cat_variable(\"FER\")\n\n\n\n\nNow that we have done some setup we need to start creating the function that will be accessing the API for us. The first step will be to provide some defaults for the year, numeric variables, categorical variables, and geography levels. Then we will include the functions that validate if the user chose the correct variables, after that we will create the base URL, then the paste function that will paste the choosen variables into the query. The GET() function will then be used to access the API and if that is successful the data will be processed with our helper function into a nice looking tibble.\n\n# Main function: Query the API\nquery_census_pums &lt;- function(\n    year = 2022,\n    numeric_vars = c(\"AGEP\", \"PWGTP\"),\n    categorical_vars = c(\"SEX\"),\n    geography_level = \"All\",\n    geography_subset = NULL\n) {\n  # Validate the year\n  validate_year(year)\n  \n  # Validate numeric variables\n  process_numeric_vars(numeric_vars)\n  \n  # Validate categorical variables\n  process_categorical_vars(categorical_vars)\n  \n  # Get API URL \n  base_url &lt;- \"https://api.census.gov/data\"\n  pathparam &lt;- \"acs/acs1/pums\"  \n  \n  # Get the full URL\n  url &lt;- paste0(base_url, \"/\", year, \"/\", pathparam, \"?get=\", \n                paste(c(numeric_vars, categorical_vars), collapse = \",\")) \n  \n  # Check geography subset and add it to API call\n  if (!is.null(geography_subset)) {\n    url &lt;- paste0(url, \"&for=\", geography_level, \":\", geography_subset)\n  }\n  print(url)\n  \n  # API call using httr::GET\n  api_response &lt;- GET(url)\n  \n  # Check if the request was successful\n  if (http_error(api_response)) {\n    stop(\"API request failed: \", status_code(api_response))\n  }\n  \n  # Process the response into a tibble\n  data &lt;- process_api_response(api_response)\n  \n  # Return the data \n  return(data)\n}\nprint(url)\n\nfunction (description, open = \"\", blocking = TRUE, encoding = getOption(\"encoding\"), \n    method = getOption(\"url.method\", \"default\"), headers = NULL) \n{\n    method &lt;- match.arg(method, c(\"default\", \"internal\", \"libcurl\", \n        \"wininet\"))\n    if (!is.null(headers)) {\n        nh &lt;- names(headers)\n        if (length(nh) != length(headers) || any(nh == \"\") || \n            anyNA(headers) || anyNA(nh)) \n            stop(\"'headers' must have names and must not be NA\")\n        headers &lt;- paste0(nh, \": \", headers)\n        headers &lt;- list(headers, paste0(headers, \"\\r\\n\", collapse = \"\"))\n    }\n    .Internal(url(description, open, blocking, encoding, method, \n        headers))\n}\n&lt;bytecode: 0x000001c77eac1378&gt;\n&lt;environment: namespace:base&gt;\n\n\nIn order to make sure that everything was running smoothly we tested the example query below:\n\n# Example for the single year 2022 with numeric and categorical variables\nresult &lt;- query_census_pums(\n  year = 2022, \n  numeric_vars = c(\"AGEP\", \"PWGTP\", \"GASP\", \"JWDP\", \"JWAP\", \"JWMNP\"),\n  categorical_vars = c(\"SEX\", \"HISPEED\", \"FER\", \"SCH\"),\n  geography_level = \"state\",\n  geography_subset = \"10\"\n)\n\nAPI year is : 2022[1] \"https://api.census.gov/data/2022/acs/acs1/pums?get=AGEP,PWGTP,GASP,JWDP,JWAP,JWMNP,SEX,HISPEED,FER,SCH&for=state:10\"\n\n\nWarning: The `x` argument of `as_tibble.matrix()` must have unique column names if\n`.name_repair` is omitted as of tibble 2.0.0.\nℹ Using compatibility `.name_repair`.\n\n#Printing results\nprint(result)\n\n# A tibble: 9,641 × 13\n    AGEP PWGTP  GASP JWMNP SEX    HISPEED    FER   SCH   state work_arrival_time\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;      &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; &lt;time&gt;           \n 1    84    76     3     0 Female N/A (GQ/v… N/A … No, … 10       NA            \n 2    39    20     3     0 Female N/A (GQ/v… No    No, … 10       NA            \n 3    19    92     3     0 Female N/A (GQ/v… No    Yes,… 10       NA            \n 4    77    19     3     0 Female N/A (GQ/v… N/A … No, … 10       NA            \n 5    18    32     3     0 Female N/A (GQ/v… No    Yes,… 10       NA            \n 6    32    80     3     0 Male   N/A (GQ/v… N/A … No, … 10       NA            \n 7    50   132     3     0 Male   N/A (GQ/v… N/A … No, … 10       NA            \n 8    23    19     3    20 Male   N/A (GQ/v… N/A … Yes,… 10    06:22            \n 9    20    47     3     0 Female N/A (GQ/v… No    Yes,… 10       NA            \n10    18   201     3     0 Female N/A (GQ/v… No    Yes,… 10       NA            \n# ℹ 9,631 more rows\n# ℹ 3 more variables: arrival_meridiem &lt;chr&gt;, work_departure_time &lt;time&gt;,\n#   departure_meridiem &lt;chr&gt;\n\n\nNow that we have validated that our query is working properly we now need to add on the ability for the user to query multiple years. In order to do this we will make a new query function that creates a loop for each year as specified by the user, and runs said loop through our initial query function in order to get data for each year. This new year data will be added to our tibble with the bind_rows() function.\n\n# 6. Function for multiple years\nquery_multiple_years &lt;- function(\n    years,                       \n    numeric_vars = c(\"AGEP\", \"PWGTP\"),  \n    categorical_vars = c(\"SEX\"),        \n    geography_level = \"All\",            \n    geography_subset = NULL             \n) {\n  all_years_data &lt;- list()\n  \n  # Loop through each year\n  for (year in years) {\n    # Check if the year is valid\n    #validate_year(year)\n    cat(\"\\nyear:\", year)\n    # Validate the year.    \n    if (year &lt; 2010 || year &gt; 2022) {\n      print(paste(\"Skipping invalid year:\", year))\n      next  # Skip this iteration and continue with the next year\n    }\n    \n    # Get data for the current year using the single year function\n    yearly_data &lt;- query_census_pums(\n      year = year,\n      numeric_vars = numeric_vars,\n      categorical_vars = categorical_vars,\n      geography_level = geography_level,\n      geography_subset = geography_subset\n    )\n    \n    # Add a year column \n    yearly_data$year &lt;- year\n    \n    # Store the current year data in the list\n    all_years_data[[as.character(year)]] &lt;- yearly_data\n  }\n  \n  # Combine all the  data into one dataset\n  final_data &lt;- bind_rows(all_years_data) \n  \n  #Adding census class to tibble\n  class(final_data) &lt;- c(\"census\", class(final_data))\n  \n  # Return dataset\n  return(final_data)\n}\n\nTesting the multi-year query to see if it is working correctly:\n\n# Example of multiple years of data\nmulti_year_result &lt;- query_multiple_years(\n  years = c( 2016, 2017, 2018),    \n  numeric_vars = c(\"AGEP\", \"PWGTP\", \"JWAP\", \"GRPIP\" ),  \n  categorical_vars = c(\"SEX\", \"HISPEED\", \"SCH\", \"FER\"),  \n  geography_level = \"state\",  \n  geography_subset = \"10\"     \n)\n\n\nyear: 2016API year is : 2016[1] \"https://api.census.gov/data/2016/acs/acs1/pums?get=AGEP,PWGTP,JWAP,GRPIP,SEX,HISPEED,SCH,FER&for=state:10\"\n\nyear: 2017API year is : 2017[1] \"https://api.census.gov/data/2017/acs/acs1/pums?get=AGEP,PWGTP,JWAP,GRPIP,SEX,HISPEED,SCH,FER&for=state:10\"\n\nyear: 2018API year is : 2018[1] \"https://api.census.gov/data/2018/acs/acs1/pums?get=AGEP,PWGTP,JWAP,GRPIP,SEX,HISPEED,SCH,FER&for=state:10\"\n\n# View the result\nprint(multi_year_result)\n\n# A tibble: 26,939 × 11\n    AGEP PWGTP GRPIP SEX    HISPEED          SCH   FER   state work_arrival_time\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;            &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; &lt;time&gt;           \n 1    51    90     0 Female Yes              No, … N/A … 10    06:12            \n 2    32   153     0 Male   Yes              No, … N/A … 10    06:02            \n 3    68    17     0 Male   N/A (GQ/vacant/… No, … N/A … 10       NA            \n 4    63    19     0 Female N/A (GQ/vacant/… No, … N/A … 10       NA            \n 5    82    34     0 Female No               No, … N/A … 10       NA            \n 6    52    65     0 Female No               No, … N/A … 10       NA            \n 7    33    80     0 Female No               No, … No    10       NA            \n 8    26    66     0 Female No               No, … No    10       NA            \n 9     3    65     0 Female No               Yes,… N/A … 10       NA            \n10    39    61     0 Female Yes              No, … No    10    11:02            \n# ℹ 26,929 more rows\n# ℹ 2 more variables: arrival_meridiem &lt;chr&gt;, year &lt;dbl&gt;\n\n\nNow we want to see if we can create another function in order to get the weighted mean and standard deviation for each of our numeric variables. This will provide the user with a useful tool to quickly acquire basic information on each variable they choose.\n\n# Define custom summary function for the 'census' class\nsummary.census &lt;- function(census_data, \n                           numeric_vars = NULL, \n                           categorical_vars = NULL) {\n  \n  # Ensure PWGTP exists and is numeric\n  if (!\"PWGTP\" %in% names(census_data)) {\n    stop(\"Weight variable 'PWGTP' is missing from the dataset.\")\n  }\n  \n  # Separate numeric and categorical columns from the data\n  if (is.null(numeric_vars)) {\n    numeric_vars &lt;- names(census_data)[sapply(census_data, is.numeric) & names(census_data) != \"PWGTP\"]\n  }\n  \n  if (is.null(categorical_vars)) {\n    categorical_vars &lt;- names(census_data)[sapply(census_data, is.factor)]\n  }\n  # Weighted mean and standard deviation calculations\n  summarize_numeric &lt;- function(var_name, data) {\n    numeric_vector &lt;- as.numeric(data[[var_name]])\n    weight_vector &lt;- as.numeric(data[[\"PWGTP\"]])\n    \n    # Check for missing values in the weight vector\n    if (any(is.na(weight_vector))) {\n      stop(\"Missing values found in the weight variable 'PWGTP'.\")\n    }\n    \n    # Calculate weighted mean\n    weighted_mean &lt;- sum(numeric_vector * weight_vector, na.rm = TRUE) / sum(weight_vector, na.rm = TRUE)\n    \n    # Calculate weighted standard deviation\n    weighted_var &lt;- sum(numeric_vector^2 * weight_vector, na.rm = TRUE) / sum(weight_vector, na.rm = TRUE)\n    weighted_sd &lt;- sqrt(weighted_var - weighted_mean^2)\n    \n    return(list(mean = weighted_mean, sd = weighted_sd))\n  }\n  \n  # Initialize a list to store the summary results\n  summary_list &lt;- list()\n  \n  # Summarize numeric variables\n  for (var in numeric_vars) {\n    summary_list[[var]] &lt;- summarize_numeric(var, census_data)\n  }\n  \n  # Summarize categorical variables (counts)\n  for (var in categorical_vars) {\n    summary_list[[var]] &lt;- table(census_data[[var]], useNA = \"ifany\")\n  }\n  \n  return(summary_list)\n}\n\nNow we are creating another function that will allow the user to create a box plot that compares a categorical variable by a numeric variable. This will provide our users with another tool to aid them in analyzing the data they query.\n\n#Creating function for user to create weighted box plots\nplot.census &lt;- function(tibble_data, categorical_var, numeric_var) {\n  \n  #Telling user they must specify at least one categorical variable\n  if (missing(categorical_var) || missing(numeric_var)){\n    stop(\"Must include one categorical variable and one numeric variable\")\n  }\n  #Telling user time variables can not be use as numeric variables\n  if (\"JWAP\" %in% numeric_var){\n    stop(\"JWAP is a time variable\")\n  }\n   if (\"JWDP\" %in% numeric_var){\n    stop(\"JWDP is a time variable\")\n  }\n  \n  p &lt;- ggplot(tibble_data, \n              aes(x = get(categorical_var), y = get(numeric_var), weight = PWGTP)) + geom_boxplot() + \n                labs(title = paste(\"Box plot of\", deparse(substitute(categorical_var)), \"by\", deparse(substitute(numeric_var))), x = categorical_var, y = numeric_var) + theme_light() \n  \n  print(p)\n}\n\n#Plot example\nplot.census(multi_year_result, \"SEX\", \"AGEP\")"
  },
  {
    "objectID": "ST558_Project_1.html#public-use-microdata-sample-pums-census-api-query",
    "href": "ST558_Project_1.html#public-use-microdata-sample-pums-census-api-query",
    "title": "ST558",
    "section": "",
    "text": "The Public Use Microdata Sample (PUMS) Census API is a freely available resource that anyone can access to acquire pseudo person-level data collected for the U.S census. In order to access this immense data set we will have to interact with the application program interface (API), which is a set of protocols and rules that allows applications to communicate with a database. In this case we are going to be using R in order to access the API, and to start we are going to need to load in some very useful packages.\nPlease read the notes in the code chunk below to better understand why we are loading in these packages:\n\nlibrary(tidycensus) #Package built to allow users to return Census Bureau API data as tibbles\nlibrary(httr) #Provides a list of easy to use statements like get() for APIs\nlibrary(jsonlite) #Package that provides a JSON parser and generator\nlibrary(dplyr) \n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tibble) #Used to create tibbles and is a part of tidyverse\nlibrary(ggplot2) #Used for plotting\nlibrary(tidyr) #Used to make data \"wide\"\nlibrary(hms) #Converts 00:00 or 00:00:00 to a time variable\nlibrary(lubridate) \n\n\nAttaching package: 'lubridate'\n\n\nThe following object is masked from 'package:hms':\n\n    hms\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\n\n\n\nThe next step we need to take is to create a helper function to assist with the query process for APIs. This function will convert the raw content to character strings, parse the JSON data, and then convert the data into a tibble. If you read through you will see that additional code has been added on that will further assist with the processing of the data we will receive from the query process. The added on functions will be explained in details later on in this document.\n\n# Helper function to process API response\nprocess_api_response &lt;- function(api_response) {\n  # Check if the response was successful\n  if (api_response$status_code != 200) {\n    stop(\"Error: API request failed with status code \", api_response$status_code)\n  }\n  \n  # Convert raw content to character string\n  content_string &lt;- rawToChar(api_response$content)\n  \n  # Parse JSON data\n  parsed_data &lt;- fromJSON(content_string)\n  \n  # First row contains column names, the rest is the data\n  column_names &lt;- parsed_data[1, ]\n  data_rows &lt;- parsed_data[-1, ]\n  \n  # Convert to tibble and set column names\n  tibble_data &lt;- as_tibble(data_rows)\n  colnames(tibble_data) &lt;- column_names\n  \n  #creating new variable in order to check if variables are numeric\n  valid_numeric_vars &lt;- c(\"AGEP\", \"GASP\", \"GRPIP\", \"JWAP\", \"JWDP\", \"JWMNP\", \"PWGTP\")\n   \n  #Created loop to convert proper numeric variables to numeric\n  for(var in colnames(tibble_data)){\n    if(var %in% valid_numeric_vars){\n      tibble_data[[var]] &lt;- as.numeric(tibble_data[[var]])\n    }\n  }\n  #New variable to check for categorical variables\n  valid_categorical_vars &lt;- c(\"FER\", \"HHL\", \"HISPEED\", \"JWTRNS\", \"SCH\", \"SCHL\", \"SEX\")\n  \n  #Created loop to convert proper categorical variables to factor\n  for(var in colnames(tibble_data)){\n    if(var %in% valid_categorical_vars){\n      tibble_data[[var]] &lt;- as.factor(tibble_data[[var]])\n    }\n  }\n  #Creating levels for each categorical variable\n  if (\"SEX\" %in% colnames(tibble_data)) {\n    tibble_data &lt;- tibble_data |&gt;\n      mutate(\n        SEX = factor(SEX, labels = SEX_levels))\n  }\n    if (\"SCHL\" %in% colnames(tibble_data)) {\n    tibble_data &lt;- tibble_data |&gt;\n      mutate(\n        SCHL = factor(SCHL, labels = SCHL_levels))\n  }\n  if (\"SCH\" %in% colnames(tibble_data)) {\n    tibble_data &lt;- tibble_data |&gt;\n      mutate(\n        SCH = factor(SCH, labels = SCH_levels))\n  }\n    if (\"JWTRNS\" %in% colnames(tibble_data)) {\n    tibble_data &lt;- tibble_data |&gt;\n      mutate(\n        JWTRNS = factor(JWTRNS, labels = JWTRNS_levels))\n    }\n    if (\"HISPEED\" %in% colnames(tibble_data)) {\n    tibble_data &lt;- tibble_data |&gt;\n      mutate(\n        HISPEED = factor(HISPEED, labels = HISPEED_levels))\n    }\n    if (\"HHL\" %in% colnames(tibble_data)) {\n    tibble_data &lt;- tibble_data |&gt;\n      mutate(\n         HHL = factor(HHL, labels =  HHL_levels))\n    }\n    if (\"FER\" %in% colnames(tibble_data)) {\n    tibble_data &lt;- tibble_data |&gt;\n      mutate(\n         FER = factor(FER, labels = FER_levels))\n  }\n  #Pasting correct time values in for JWAP\n  if(\"JWAP\" %in% colnames(tibble_data)) {\n  tibble_data &lt;- tibble_data |&gt;\n   left_join(JWAP_intervals, join_by(JWAP)) |&gt;\n    rename(work_arrival_time = middle_time,\n           arrival_meridiem = meridiem) |&gt;\n    select(-JWAP)\n  } \n  \n  #Pasting correct time values in for JWDP\n   if(\"JWDP\" %in% colnames(tibble_data)) {\n  tibble_data &lt;- tibble_data |&gt;\n   left_join(JWDP_intervals, join_by(JWDP)) |&gt;\n    rename(work_departure_time = middle_time2,\n           departure_meridiem = meridiem2) |&gt;\n    select(-JWDP)\n  } \n  \n  return(tibble_data)\n}\n\nThe next step is to create a year validation function in order to confirm only the correct years (2022 to 2010) are queried by the user. This function alongside other subsequent ones will be added to the main API query that we are creating, that way we can insure a user only selects variables that will work with our API query.\n\n# Function to validate the year\nvalidate_year &lt;- function(year) {\n  cat(\"API year is :\", year)\n  if (year &lt; 2010 || year &gt; 2022) {\n    stop(\"Invalid year. Year must be between 2010 and 2022.\")\n  }\n}\n\nAfter we create our year validation function we make another function that insures our user will only select the valid numeric and categorical variables our query will work with, and if the user does not select these variables they will get an error message letting them know what variables they can use instead. Additionally, the function insures that the PWGTP variable is always included with our query, as that variable is a representation of the number of people each row actually represents, specifically it is our weight variable.\n\n# Function to validate numeric variables\nprocess_numeric_vars &lt;- function(numeric_vars = c(\"AGEP\", \"PWGTP\")) {\n  valid_numeric_vars &lt;- c(\"AGEP\", \"GASP\", \"GRPIP\", \"JWAP\", \"JWDP\", \"JWMNP\", \"PWGTP\")\n  \n  # Check PWGTP is always included\n  if (!\"PWGTP\" %in% numeric_vars) {\n    numeric_vars &lt;- c(numeric_vars, \"PWGTP\")\n  }\n  \n  # Validate numeric variables\n  if (!all(numeric_vars %in% valid_numeric_vars)) {\n    stop(\"Invalid numeric variables. Valid options: AGEP, GASP, GRPIP, JWAP, JWDP, JWMNP, PWGTP.\")\n  }\n  \n  # Check at least one numeric variable other than PWGTP\n  if (!any(numeric_vars %in% valid_numeric_vars[valid_numeric_vars != \"PWGTP\"])) {\n    stop(\"At least one numeric variable other than PWGTP must be returned.\")\n  } \n} \n\n# Function to validate categorical variables\nprocess_categorical_vars &lt;- function(categorical_vars = c(\"SEX\")) {\n  valid_categorical_vars &lt;- c(\"FER\", \"HHL\", \"HISPEED\", \"JWTRNS\", \"SCH\", \"SCHL\", \"SEX\")\n  \n  # Validate categorical variables\n  if (!all(categorical_vars %in% valid_categorical_vars)) {\n    stop(\"Invalid categorical variables. Valid options: FER, HHL, HISPEED, JWAP, JWDP, JWTRNS, SCH, SCHL, SEX.\")\n  }\n  return(categorical_vars)\n}\n\nLooking ahead when we pull the time variables JWAP and JWDP out of the API they appear as character strings that represent a time interval for the period in which a person generally begins work, such as 09:00 a.m to 09:04 a.m. This proves to be a problem for us as we we can not present the interval in a neat easily understandable manner for the user, so to make things more consistent and readable we will have the time variables return as the middle time between the interval. To do this is quite a complicated tasks, and will require the usage of the readr which will allow us to separate the character strings into usable columns. Due to the complexity of this we are going to extract the exact data for the whole variable in the API, then use separate_wider_delim to create two columns that represent the start and end of the time variable. Since the time variables are represented in the character strings as “00:00” we can use the parse_hm() function to have the columns for the start and end of the intervals represented in HH:MM:SS format, once they are in that format the start and end columns can be subtracted then divided by two and added to the start to get the middle of the interval for each observation. In order to aid readability the time variables are going to be renamed to work_arrival_time or work_departure_time, in addition the proper am or pm designation columns (meridian) will appear next to the variables. That way the user will still be able to manipulate the variables as a time variable and know if the variable is for the morning or night.\n\n# Function to process time variables\nprocess_time_variable &lt;- function(variable_name) {\n \n   # Grabbing information from API\n  temp &lt;- httr::GET(paste0(\"https://api.census.gov/data/2022/acs/acs1/pums/variables/\", variable_name, \".json\"))\n  temp_list &lt;- temp$content |&gt; rawToChar() |&gt; jsonlite::fromJSON()\n  \n  # Getting just the variable names and their values\n  time_values &lt;- temp_list$values$item\n  time_vals_sorted &lt;- time_values[sort(names(time_values))]\n  \n  # Converting the values into a tibble\n  time_tibble &lt;- tibble(id = seq(0, length(time_vals_sorted) - 1), value = time_vals_sorted)\n  \n  # Converting to wide format\n  time_wide &lt;- separate_wider_delim(time_tibble, \n                                     cols = c(\"value\"), \n                                     delim = \" \", \n                                     names = c(\"start\", \"meridiem\", \"to\", \"end\", \"meridiem_2\"), \n                                     too_few = \"debug\", \n                                     names_repair = \"unique\", \n                                     too_many = \"drop\") \n  \n  # Select the needed rows and convert to usable format\n  time_intervals &lt;- time_wide |&gt;\n    select(id, start, meridiem, end, meridiem_2) |&gt; #meridiem is to track if values were for am or pm\n    mutate(start = parse_hm(start),\n           end = parse_hm(end),\n           variable_name = id)  \n  \n  # Make row 1 display NA across all columns for row 1    \n  time_intervals[1, ] &lt;- NA\n  \n  # Creating middle time value variable\n  time_intervals &lt;- time_intervals |&gt;\n    mutate(interval = (end - start) / 2,\n           interval = as.numeric(interval),\n           interval = as.period(interval))\n\n  # Turning start into a period   \n  time_intervals &lt;- time_intervals |&gt;\n    mutate(start = as.period(start),\n           middle_time = as.duration(start + interval)) |&gt;\n    select(middle_time, variable_name, meridiem) \n  \n  # Turning the first row variable back to 0\n  time_intervals[1, 2] &lt;- 0\n          \n  # Converting back to a time variable        \n  time_intervals &lt;- time_intervals |&gt;\n    mutate(middle_time = hms::hms(seconds = middle_time))\n  \n  return(time_intervals)\n} \n\n#Renaming variables to insure they work in the helper function\nJWAP_intervals &lt;- process_time_variable(\"JWAP\")\n\nWarning: Debug mode activated: adding variables `value_ok`, `value_pieces`, and\n`value_remainder`.\n\nJWAP_intervals &lt;- JWAP_intervals |&gt;\n  rename(JWAP = variable_name)\n         \nJWDP_intervals &lt;- process_time_variable(\"JWDP\")\n\nWarning: Debug mode activated: adding variables `value_ok`, `value_pieces`, and\n`value_remainder`.\n\nJWDP_intervals &lt;- JWDP_intervals |&gt;\n  rename(JWDP = variable_name,\n         middle_time2 = middle_time,\n         meridiem2 = meridiem)\n\nWhen we look at ahead we realize that if we pull in our categorical data we will not necessarily understand it as it is lacking the proper levels for the data contained, necessitating that we create proper level keys for the variables we will be querying. This will follow a similar process to how we got the time variables, but will be much simpler. Once we acquire the necessary levels we will go back in to our helper function to convert the categorical variables to factors and include the proper levels and labels for each one.\n\n# Function to process categorical variables\nprocess_cat_variable &lt;- function(variable_name) {\n \n   # Grabbing information from API\n  temp &lt;- httr::GET(paste0(\"https://api.census.gov/data/2022/acs/acs1/pums/variables/\", variable_name, \".json\"))\n  temp_list &lt;- temp$content |&gt; rawToChar() |&gt; jsonlite::fromJSON()\n  \n  # Getting just the variable names and their values\n  cat_values &lt;- temp_list$values$item\n  cat_vals_sorted &lt;- cat_values[sort(names(cat_values))]\n  \n  # Converting the values into a tibble\n  cat_tibble &lt;- tibble(id = seq(0, length(cat_vals_sorted) - 1), value = cat_vals_sorted)\n  cat_vector &lt;- cat_tibble$value\n  \n  return(cat_vector)\n}\n\n#Running function for categorical variables to store levels\nSCHL_levels &lt;- process_cat_variable(\"SCHL\")\nSEX_levels &lt;- process_cat_variable(\"SEX\")\nSCH_levels &lt;- process_cat_variable(\"SCH\")\nJWTRNS_levels &lt;- process_cat_variable(\"JWTRNS\")\nHISPEED_levels &lt;- process_cat_variable(\"HISPEED\")\nHHL_levels &lt;- process_cat_variable(\"HHL\")\nFER_levels &lt;- process_cat_variable(\"FER\")\n\n\n\n\nNow that we have done some setup we need to start creating the function that will be accessing the API for us. The first step will be to provide some defaults for the year, numeric variables, categorical variables, and geography levels. Then we will include the functions that validate if the user chose the correct variables, after that we will create the base URL, then the paste function that will paste the choosen variables into the query. The GET() function will then be used to access the API and if that is successful the data will be processed with our helper function into a nice looking tibble.\n\n# Main function: Query the API\nquery_census_pums &lt;- function(\n    year = 2022,\n    numeric_vars = c(\"AGEP\", \"PWGTP\"),\n    categorical_vars = c(\"SEX\"),\n    geography_level = \"All\",\n    geography_subset = NULL\n) {\n  # Validate the year\n  validate_year(year)\n  \n  # Validate numeric variables\n  process_numeric_vars(numeric_vars)\n  \n  # Validate categorical variables\n  process_categorical_vars(categorical_vars)\n  \n  # Get API URL \n  base_url &lt;- \"https://api.census.gov/data\"\n  pathparam &lt;- \"acs/acs1/pums\"  \n  \n  # Get the full URL\n  url &lt;- paste0(base_url, \"/\", year, \"/\", pathparam, \"?get=\", \n                paste(c(numeric_vars, categorical_vars), collapse = \",\")) \n  \n  # Check geography subset and add it to API call\n  if (!is.null(geography_subset)) {\n    url &lt;- paste0(url, \"&for=\", geography_level, \":\", geography_subset)\n  }\n  print(url)\n  \n  # API call using httr::GET\n  api_response &lt;- GET(url)\n  \n  # Check if the request was successful\n  if (http_error(api_response)) {\n    stop(\"API request failed: \", status_code(api_response))\n  }\n  \n  # Process the response into a tibble\n  data &lt;- process_api_response(api_response)\n  \n  # Return the data \n  return(data)\n}\nprint(url)\n\nfunction (description, open = \"\", blocking = TRUE, encoding = getOption(\"encoding\"), \n    method = getOption(\"url.method\", \"default\"), headers = NULL) \n{\n    method &lt;- match.arg(method, c(\"default\", \"internal\", \"libcurl\", \n        \"wininet\"))\n    if (!is.null(headers)) {\n        nh &lt;- names(headers)\n        if (length(nh) != length(headers) || any(nh == \"\") || \n            anyNA(headers) || anyNA(nh)) \n            stop(\"'headers' must have names and must not be NA\")\n        headers &lt;- paste0(nh, \": \", headers)\n        headers &lt;- list(headers, paste0(headers, \"\\r\\n\", collapse = \"\"))\n    }\n    .Internal(url(description, open, blocking, encoding, method, \n        headers))\n}\n&lt;bytecode: 0x000001c77eac1378&gt;\n&lt;environment: namespace:base&gt;\n\n\nIn order to make sure that everything was running smoothly we tested the example query below:\n\n# Example for the single year 2022 with numeric and categorical variables\nresult &lt;- query_census_pums(\n  year = 2022, \n  numeric_vars = c(\"AGEP\", \"PWGTP\", \"GASP\", \"JWDP\", \"JWAP\", \"JWMNP\"),\n  categorical_vars = c(\"SEX\", \"HISPEED\", \"FER\", \"SCH\"),\n  geography_level = \"state\",\n  geography_subset = \"10\"\n)\n\nAPI year is : 2022[1] \"https://api.census.gov/data/2022/acs/acs1/pums?get=AGEP,PWGTP,GASP,JWDP,JWAP,JWMNP,SEX,HISPEED,FER,SCH&for=state:10\"\n\n\nWarning: The `x` argument of `as_tibble.matrix()` must have unique column names if\n`.name_repair` is omitted as of tibble 2.0.0.\nℹ Using compatibility `.name_repair`.\n\n#Printing results\nprint(result)\n\n# A tibble: 9,641 × 13\n    AGEP PWGTP  GASP JWMNP SEX    HISPEED    FER   SCH   state work_arrival_time\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;      &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; &lt;time&gt;           \n 1    84    76     3     0 Female N/A (GQ/v… N/A … No, … 10       NA            \n 2    39    20     3     0 Female N/A (GQ/v… No    No, … 10       NA            \n 3    19    92     3     0 Female N/A (GQ/v… No    Yes,… 10       NA            \n 4    77    19     3     0 Female N/A (GQ/v… N/A … No, … 10       NA            \n 5    18    32     3     0 Female N/A (GQ/v… No    Yes,… 10       NA            \n 6    32    80     3     0 Male   N/A (GQ/v… N/A … No, … 10       NA            \n 7    50   132     3     0 Male   N/A (GQ/v… N/A … No, … 10       NA            \n 8    23    19     3    20 Male   N/A (GQ/v… N/A … Yes,… 10    06:22            \n 9    20    47     3     0 Female N/A (GQ/v… No    Yes,… 10       NA            \n10    18   201     3     0 Female N/A (GQ/v… No    Yes,… 10       NA            \n# ℹ 9,631 more rows\n# ℹ 3 more variables: arrival_meridiem &lt;chr&gt;, work_departure_time &lt;time&gt;,\n#   departure_meridiem &lt;chr&gt;\n\n\nNow that we have validated that our query is working properly we now need to add on the ability for the user to query multiple years. In order to do this we will make a new query function that creates a loop for each year as specified by the user, and runs said loop through our initial query function in order to get data for each year. This new year data will be added to our tibble with the bind_rows() function.\n\n# 6. Function for multiple years\nquery_multiple_years &lt;- function(\n    years,                       \n    numeric_vars = c(\"AGEP\", \"PWGTP\"),  \n    categorical_vars = c(\"SEX\"),        \n    geography_level = \"All\",            \n    geography_subset = NULL             \n) {\n  all_years_data &lt;- list()\n  \n  # Loop through each year\n  for (year in years) {\n    # Check if the year is valid\n    #validate_year(year)\n    cat(\"\\nyear:\", year)\n    # Validate the year.    \n    if (year &lt; 2010 || year &gt; 2022) {\n      print(paste(\"Skipping invalid year:\", year))\n      next  # Skip this iteration and continue with the next year\n    }\n    \n    # Get data for the current year using the single year function\n    yearly_data &lt;- query_census_pums(\n      year = year,\n      numeric_vars = numeric_vars,\n      categorical_vars = categorical_vars,\n      geography_level = geography_level,\n      geography_subset = geography_subset\n    )\n    \n    # Add a year column \n    yearly_data$year &lt;- year\n    \n    # Store the current year data in the list\n    all_years_data[[as.character(year)]] &lt;- yearly_data\n  }\n  \n  # Combine all the  data into one dataset\n  final_data &lt;- bind_rows(all_years_data) \n  \n  #Adding census class to tibble\n  class(final_data) &lt;- c(\"census\", class(final_data))\n  \n  # Return dataset\n  return(final_data)\n}\n\nTesting the multi-year query to see if it is working correctly:\n\n# Example of multiple years of data\nmulti_year_result &lt;- query_multiple_years(\n  years = c( 2016, 2017, 2018),    \n  numeric_vars = c(\"AGEP\", \"PWGTP\", \"JWAP\", \"GRPIP\" ),  \n  categorical_vars = c(\"SEX\", \"HISPEED\", \"SCH\", \"FER\"),  \n  geography_level = \"state\",  \n  geography_subset = \"10\"     \n)\n\n\nyear: 2016API year is : 2016[1] \"https://api.census.gov/data/2016/acs/acs1/pums?get=AGEP,PWGTP,JWAP,GRPIP,SEX,HISPEED,SCH,FER&for=state:10\"\n\nyear: 2017API year is : 2017[1] \"https://api.census.gov/data/2017/acs/acs1/pums?get=AGEP,PWGTP,JWAP,GRPIP,SEX,HISPEED,SCH,FER&for=state:10\"\n\nyear: 2018API year is : 2018[1] \"https://api.census.gov/data/2018/acs/acs1/pums?get=AGEP,PWGTP,JWAP,GRPIP,SEX,HISPEED,SCH,FER&for=state:10\"\n\n# View the result\nprint(multi_year_result)\n\n# A tibble: 26,939 × 11\n    AGEP PWGTP GRPIP SEX    HISPEED          SCH   FER   state work_arrival_time\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;            &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; &lt;time&gt;           \n 1    51    90     0 Female Yes              No, … N/A … 10    06:12            \n 2    32   153     0 Male   Yes              No, … N/A … 10    06:02            \n 3    68    17     0 Male   N/A (GQ/vacant/… No, … N/A … 10       NA            \n 4    63    19     0 Female N/A (GQ/vacant/… No, … N/A … 10       NA            \n 5    82    34     0 Female No               No, … N/A … 10       NA            \n 6    52    65     0 Female No               No, … N/A … 10       NA            \n 7    33    80     0 Female No               No, … No    10       NA            \n 8    26    66     0 Female No               No, … No    10       NA            \n 9     3    65     0 Female No               Yes,… N/A … 10       NA            \n10    39    61     0 Female Yes              No, … No    10    11:02            \n# ℹ 26,929 more rows\n# ℹ 2 more variables: arrival_meridiem &lt;chr&gt;, year &lt;dbl&gt;\n\n\nNow we want to see if we can create another function in order to get the weighted mean and standard deviation for each of our numeric variables. This will provide the user with a useful tool to quickly acquire basic information on each variable they choose.\n\n# Define custom summary function for the 'census' class\nsummary.census &lt;- function(census_data, \n                           numeric_vars = NULL, \n                           categorical_vars = NULL) {\n  \n  # Ensure PWGTP exists and is numeric\n  if (!\"PWGTP\" %in% names(census_data)) {\n    stop(\"Weight variable 'PWGTP' is missing from the dataset.\")\n  }\n  \n  # Separate numeric and categorical columns from the data\n  if (is.null(numeric_vars)) {\n    numeric_vars &lt;- names(census_data)[sapply(census_data, is.numeric) & names(census_data) != \"PWGTP\"]\n  }\n  \n  if (is.null(categorical_vars)) {\n    categorical_vars &lt;- names(census_data)[sapply(census_data, is.factor)]\n  }\n  # Weighted mean and standard deviation calculations\n  summarize_numeric &lt;- function(var_name, data) {\n    numeric_vector &lt;- as.numeric(data[[var_name]])\n    weight_vector &lt;- as.numeric(data[[\"PWGTP\"]])\n    \n    # Check for missing values in the weight vector\n    if (any(is.na(weight_vector))) {\n      stop(\"Missing values found in the weight variable 'PWGTP'.\")\n    }\n    \n    # Calculate weighted mean\n    weighted_mean &lt;- sum(numeric_vector * weight_vector, na.rm = TRUE) / sum(weight_vector, na.rm = TRUE)\n    \n    # Calculate weighted standard deviation\n    weighted_var &lt;- sum(numeric_vector^2 * weight_vector, na.rm = TRUE) / sum(weight_vector, na.rm = TRUE)\n    weighted_sd &lt;- sqrt(weighted_var - weighted_mean^2)\n    \n    return(list(mean = weighted_mean, sd = weighted_sd))\n  }\n  \n  # Initialize a list to store the summary results\n  summary_list &lt;- list()\n  \n  # Summarize numeric variables\n  for (var in numeric_vars) {\n    summary_list[[var]] &lt;- summarize_numeric(var, census_data)\n  }\n  \n  # Summarize categorical variables (counts)\n  for (var in categorical_vars) {\n    summary_list[[var]] &lt;- table(census_data[[var]], useNA = \"ifany\")\n  }\n  \n  return(summary_list)\n}\n\nNow we are creating another function that will allow the user to create a box plot that compares a categorical variable by a numeric variable. This will provide our users with another tool to aid them in analyzing the data they query.\n\n#Creating function for user to create weighted box plots\nplot.census &lt;- function(tibble_data, categorical_var, numeric_var) {\n  \n  #Telling user they must specify at least one categorical variable\n  if (missing(categorical_var) || missing(numeric_var)){\n    stop(\"Must include one categorical variable and one numeric variable\")\n  }\n  #Telling user time variables can not be use as numeric variables\n  if (\"JWAP\" %in% numeric_var){\n    stop(\"JWAP is a time variable\")\n  }\n   if (\"JWDP\" %in% numeric_var){\n    stop(\"JWDP is a time variable\")\n  }\n  \n  p &lt;- ggplot(tibble_data, \n              aes(x = get(categorical_var), y = get(numeric_var), weight = PWGTP)) + geom_boxplot() + \n                labs(title = paste(\"Box plot of\", deparse(substitute(categorical_var)), \"by\", deparse(substitute(numeric_var))), x = categorical_var, y = numeric_var) + theme_light() \n  \n  print(p)\n}\n\n#Plot example\nplot.census(multi_year_result, \"SEX\", \"AGEP\")"
  },
  {
    "objectID": "ST558_Project_1.html#census-api-investigation",
    "href": "ST558_Project_1.html#census-api-investigation",
    "title": "ST558",
    "section": "Census API Investigation",
    "text": "Census API Investigation\nNow that we have created our functions and API Query we need to use it to analyze some data. Something interesting may come from analyzing gross rent as a percentage of household income of the past 12 months (GRPIP), and see what we may find relating to it. In particular I want to examine the relationship between household language spoken at home (HHL) and the variable GRPIP\n\n# Query\nrent_query &lt;- query_multiple_years(\n  years = c(2022),    \n  numeric_vars = c(\"AGEP\", \"GRPIP\", \"PWGTP\" ),  \n  categorical_vars = c(\"SEX\", \"HHL\"),  \n  geography_level = \"state\",  \n  geography_subset = \"10\"     \n) \n\n\nyear: 2022API year is : 2022[1] \"https://api.census.gov/data/2022/acs/acs1/pums?get=AGEP,GRPIP,PWGTP,SEX,HHL&for=state:10\"\n\nprint(rent_query)\n\n# A tibble: 9,641 × 7\n    AGEP GRPIP PWGTP SEX    HHL     state  year\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;   &lt;chr&gt; &lt;dbl&gt;\n 1    60     0    82 Female Spanish 10     2022\n 2    61     0   101 Male   Spanish 10     2022\n 3    31     0   149 Female Spanish 10     2022\n 4    28     0   106 Female Spanish 10     2022\n 5    69     0   132 Female Spanish 10     2022\n 6    30     0    76 Female Spanish 10     2022\n 7    32     0   198 Male   Spanish 10     2022\n 8    12     0   169 Male   Spanish 10     2022\n 9     3     0   564 Female Spanish 10     2022\n10     0     0   564 Female Spanish 10     2022\n# ℹ 9,631 more rows\n\n\nNow the next thing I want to do is use our summary function to get a basic overview of the data we will be working with.\n\n# Summary Function\nrent_query_summary &lt;- summary.census(rent_query)\n# Printing results\nrent_query_summary\n\n$AGEP\n$AGEP$mean\n[1] 41.56009\n\n$AGEP$sd\n[1] 23.81078\n\n\n$GRPIP\n$GRPIP$mean\n[1] 7.823032\n\n$GRPIP$sd\n[1] 19.05969\n\n\n$year\n$year$mean\n[1] 2022\n\n$year$sd\n[1] 0\n\n\n$SEX\n\n  Male Female \n  4534   5107 \n\n$HHL\n\n                   N/A (GQ/vacant)                       English Only \n                               305                               7819 \n                           Spanish      Other Indo-European languages \n                               703                                381 \nAsian and Pacific Island languages                     Other Language \n                               252                                181 \n\n\nWe can now see that the mean age is 41.56 years with a standard deviation of 23.81 years, and the mean gross rent as percentage of household income is 7.82% with a standard deviation of 19.06%. The reason for the large standard deviation is that many individuals do not buy rent as they may own their own house, meaning many individuals pay 0% of their household income in rent.\nIn order to get a better picture of the categorical variables we are going to write some quick code to determine the total percent for each level for SEX and HHL. In order to do this we need to create weighted counts for the variables that we will be looking at.\n\n#Function to give weighted counts \npercent.summary &lt;- function(query, cat_var = \"SEX\", weight = \"PWGTP\"){\n  weight_query &lt;- query |&gt;\n    select(!!sym(cat_var), !!sym(weight)) |&gt;\n    group_by(!!sym(cat_var)) |&gt;\n    summarize(weighted_var = sum(!!sym(weight)))\n  \n  #creating a total column to create percentages  \n  weight_query &lt;- weight_query |&gt;\n    mutate(total = sum(weighted_var),\n           percentage = (weighted_var / total) * 100) |&gt;\n    select(cat_var, weighted_var, percentage)\n  \n  return(weight_query)\n} \n\n#creating summary tables for variables\npercent.summary(rent_query, \"SEX\")\n\nWarning: Using an external vector in selections was deprecated in tidyselect 1.1.0.\nℹ Please use `all_of()` or `any_of()` instead.\n  # Was:\n  data %&gt;% select(cat_var)\n\n  # Now:\n  data %&gt;% select(all_of(cat_var))\n\nSee &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;.\n\n\n# A tibble: 2 × 3\n  SEX    weighted_var percentage\n  &lt;fct&gt;         &lt;dbl&gt;      &lt;dbl&gt;\n1 Male         493340       48.4\n2 Female       525056       51.6\n\npercent.summary(rent_query, \"HHL\")\n\n# A tibble: 6 × 3\n  HHL                                weighted_var percentage\n  &lt;fct&gt;                                     &lt;dbl&gt;      &lt;dbl&gt;\n1 N/A (GQ/vacant)                           22688       2.23\n2 English Only                             803203      78.9 \n3 Spanish                                   96655       9.49\n4 Other Indo-European languages             41809       4.11\n5 Asian and Pacific Island languages        30577       3.00\n6 Other Language                            23464       2.30\n\n#Converting summary tables to \n\nBased on the results from running our function, we can find that about 48.4% of the individuals in our query are male and 51.6% are female. In terms of household languages we find that about 78.9% of the individuals in our query speak English at home, 9.49% speak Spanish, 4.11% speak other Indo-European languages, 2.23% were listed as N/A, 3.0% speak an Asian or Pacific Island language, and 2.3% speak another language not listed.\nNow we are going to use our plot function to compare household language spoken at home by household income paid in gross rent.\n\nplot.census(rent_query, \"HHL\", \"GRPIP\")\n\n\n\n\n\n\n\n\nAs we can see from our results due to many people not paying any household income in rent that the data becomes hard to read in a box plot format, so lets take away any values equal to zero to get a better look at the data just for individuals who do pay for rent. To do this we are going to use the filter function to take out each observation in our data set where GRPIP is equal to zero.\n\n#filtering out non-renters\nrenters_only &lt;- rent_query |&gt;\n  filter(GRPIP != 0) #only returning data where GRPIP does not equal 0\n\n#New plot only of renters\nrenters_only_plot &lt;- plot.census(renters_only, \"HHL\", \"GRPIP\")\n\n\n\n\n\n\n\nrenters_only_plot\n\n\n\n\n\n\n\n\nNow it is much easier to look at the data for renters only, but before we do any further analysis I wanted to see the difference in which percent of each household language group was paying rent or not paying rent.\n\n#Filtering so only non-renters only are returned\nnonrenters_only &lt;- rent_query |&gt;\n  filter(GRPIP == 0) \n\n\n#Using percent.summary to find percentages \nnonrenters_tibble &lt;- percent.summary(nonrenters_only, \"HHL\")\nnonrenters_tibble &lt;- nonrenters_tibble |&gt;\n  mutate(total = sum(weighted_var)) # grabbing total for anylasis purposes\n\nrenters_tibble &lt;- percent.summary(renters_only, \"HHL\")\nrenters_tibble &lt;- renters_tibble |&gt;\n  mutate(total = sum(weighted_var))\n\n#Printing tables\nnonrenters_tibble\n\n# A tibble: 6 × 4\n  HHL                                weighted_var percentage  total\n  &lt;fct&gt;                                     &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;\n1 N/A (GQ/vacant)                           22688       2.86 791938\n2 English Only                             638969      80.7  791938\n3 Spanish                                   60292       7.61 791938\n4 Other Indo-European languages             31572       3.99 791938\n5 Asian and Pacific Island languages        22315       2.82 791938\n6 Other Language                            16102       2.03 791938\n\nrenters_tibble \n\n# A tibble: 5 × 4\n  HHL                                weighted_var percentage  total\n  &lt;fct&gt;                                     &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;\n1 English Only                             164234      72.5  226458\n2 Spanish                                   36363      16.1  226458\n3 Other Indo-European languages             10237       4.52 226458\n4 Asian and Pacific Island languages         8262       3.65 226458\n5 Other Language                             7362       3.25 226458\n\n#Calculating percent non-renters and renters\ntotal_renters &lt;- (226458 / (226458 + 791938)) * 100 \ntotal_renters\n\n[1] 22.23673\n\ntotal_nonrenters &lt;- 100 - total_renters \ntotal_nonrenters\n\n[1] 77.76327\n\n\nBased off these results, we have found that renters make up 22.24% and non-renters make up 77.76% of the individuals in our query. In terms of percents of non-renters by household spoken language we found that 80.7% speak English at home, 7.61% speak Spanish at home, 3.99% speak another Indo-European language at home, 2.82% speak an Asian or Pacific Island language at home, 2.03% speak some other langauge at home, and 2.86% were marked as NA. In terms of percents of renters by household spoken language we found that 72.5% speak English at home, 16.1% speak Spanish at home, 4.52% speak another Indo-European language at home, 3.65% speak an Asian or Pacific Island language at home, and 3.25% speak some other language at home. English only speakers appear to be over represented among the non-renters compared to their portion of the data set, as we would expect the percentages between non-renters and renters to be consistent between household language spoken at home. This may suggest that household language spoken at home is correlated with not renting, but further analysis would need to be undertaken to come to the conclusion a relationship exist.\nNow to go back to our initial interest, we need to look back at out box plots of non-renters by gross percent of household income spent on renting. Looking at the box plots we can see that the average percent for all groups ranges from roughly 15 to 30 percent, with Spanish speakers having the highest percent and Other Indo-European Language speakers having the lowest average percent. In terms of spread English only, Spanish only, and Asian and Pacific Island Languages group have fairly large spreads for their IQRs. The other language group has the smallest IQR and overall has the shortest range, that is noticeable pronounced when excluding outliers. While the reason for the difference in average percents and range can not be parsed out by this short initial analysis it is clear that there is a wide range of variance between the groups indicating some other factors may be at play. A future analysis should look into if there is a correlation between income or wealth and household language spoken at home, as that may be influencing the data.\n\nrenters_only_plot"
  }
]